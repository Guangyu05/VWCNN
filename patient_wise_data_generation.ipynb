{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e682b14c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2009"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import   pickle\n",
    "import collections\n",
    "import os\n",
    "import numpy as np\n",
    "import random \n",
    "\n",
    "infile = open('cv_split_5_fold_seizure_wise_v1.4.0.pkl','rb') #use the data prepared for cross validation\n",
    "new_dict = pickle.load(infile)\n",
    "infile.close()\n",
    "\n",
    "source  = 'processed_2/v1.4.0/fft/fft_seizures_wl1_ws_0.25_sf_250_fft_min_1_fft_max_24/' #load the data from this folder\n",
    "\n",
    "source  = 'processed_2/v1.4.0/fft/fft_seizures_wl1_ws_0.25_sf_250_fft_min_1_fft_max_24/'\n",
    "arr = os.listdir(source)\n",
    "\n",
    "for file in arr:\n",
    "    if 'MYSZ'in file:\n",
    "        arr.remove(file)\n",
    "        \n",
    "len(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9f7fce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#record all the patient-ID\n",
    "patient_id = set()\n",
    "for file in arr:\n",
    "    patient_id.add(file.split('_')[3])\n",
    "len(patient_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "551d3720",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "np.random.seed(seed) # Reset the seed so all runs are the same.\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "401277cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-b497d4e16f73>:1: DeprecationWarning: Sampling from a set deprecated\n",
      "since Python 3.9 and will be removed in a subsequent version.\n",
      "  test_patients = random.sample(patient_id, 30)\n"
     ]
    }
   ],
   "source": [
    "test_patients = random.sample(patient_id, 30)\n",
    "train_patients = patient_id.difference(test_patients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e29c929",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = []\n",
    "train_set = []\n",
    "for file in arr:\n",
    "    pid = file.split('_')[3]\n",
    "    if pid in test_patients:\n",
    "        test_set.append(file)\n",
    "    else:\n",
    "        train_set.append(file)\n",
    "\n",
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7ceec1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABSZ': {'00002657', '00000675', '00003281'}, 'CPSZ': {'00006413', '00008615', '00005347', '00005479'}, 'FNSZ': {'00010547', '00005479', '00004596', '00009697', '00006440', '00001479', '00006563', '00007584', '00009570', '00008174', '00006444', '00001548', '00009842', '00003760', '00007196', '00003884', '00005346', '00010062', '00001116', '00006507'}, 'GNSZ': {'00006563', '00005034', '00008174', '00009162', '00010020', '00006440', '00010062'}, 'SPSZ': set(), 'TCSZ': {'00005804'}, 'TNSZ': set()}\n"
     ]
    }
   ],
   "source": [
    "table_test = {'ABSZ':set(),'CPSZ':set(), 'FNSZ':set(), 'GNSZ':set(), 'SPSZ':set(), 'TCSZ':set(), 'TNSZ':set()}\n",
    "for file in test_set:\n",
    "    stype = file.split('_')[-1][:4]\n",
    "    pid = file.split('_')[3]\n",
    "    table_test[stype].add(pid)\n",
    "   \n",
    "print(table_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d70e959c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABSZ': {'00001984', '00003306', '00001795', '00008608', '00001413', '00003053', '00001113', '00003635', '00002448'}, 'CPSZ': {'00007032', '00008295', '00006000', '00008544', '00004126', '00006514', '00004892', '00003977', '00000609', '00000021', '00001027', '00006535', '00005633', '00006986', '00007128', '00002806', '00005672', '00006546', '00002297', '00000006', '00006811', '00008453', '00008460', '00005512', '00006904', '00008029', '00006083', '00000883', '00005452', '00005044'}, 'FNSZ': {'00002484', '00004523', '00008512', '00005101', '00007793', '00007092', '00009885', '00006175', '00003401', '00005426', '00005625', '00002445', '00006230', '00008092', '00009050', '00002521', '00007835', '00010106', '00007234', '00010587', '00005943', '00010022', '00000883', '00001324', '00005427', '00007235', '00000302', '00001981', '00008295', '00000574', '00006103', '00008544', '00006514', '00004049', '00000281', '00009107', '00007128', '00006546', '00009934', '00008552', '00004434', '00006811', '00008480', '00002991', '00008476', '00008029', '00003208', '00009158', '00009866', '00001753', '00004473', '00010489', '00001027', '00006535', '00006351', '00002868', '00009104', '00010418', '00000529', '00007797', '00004569', '00002427', '00001543', '00010427', '00007032', '00010591', '00009578', '00009630', '00006139', '00002707', '00005371', '00002806', '00005672', '00000473', '00007623', '00009852', '00004087', '00007095', '00008460', '00007130', '00000258', '00007952', '00001052', '00006251', '00008889', '00001843', '00005213', '00004151', '00009839'}, 'GNSZ': {'00007032', '00008512', '00005101', '00000975', '00010861', '00008479', '00006514', '00004671', '00007128', '00002868', '00007170', '00006546', '00009934', '00006520', '00006230', '00008303', '00004087', '00004456', '00008480', '00008453', '00000820', '00002521', '00010421', '00001587', '00000492', '00006107', '00010106', '00009232', '00001543', '00009158', '00007952', '00009623', '00001006', '00010639', '00010158', '00009839', '00000302'}, 'SPSZ': {'00006546', '00008616'}, 'TCSZ': {'00001770', '00000775', '00000258', '00000906', '00009578', '00008889', '00005426', '00010158', '00006546', '00006520'}, 'TNSZ': {'00008444', '00008889'}}\n"
     ]
    }
   ],
   "source": [
    "table_train = {'ABSZ':set(),'CPSZ':set(), 'FNSZ':set(), 'GNSZ':set(), 'SPSZ':set(), 'TCSZ':set(), 'TNSZ':set()}\n",
    "for file in train_set:\n",
    "    stype = file.split('_')[-1][:4]\n",
    "    pid = file.split('_')[3]\n",
    "    table_train[stype].add(pid)\n",
    "\n",
    "print(table_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5c32a7d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As test data does not have samples of the class 'TNSZ', extract a patient' samples from the training set and add them to the test set.  \n",
    "for file in train_set:\n",
    "    pid = file.split('_')[3]\n",
    "    if pid == '00008444':\n",
    "        test_set.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "194cb599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ABSZ': {'00002657', '00000675', '00003281'}, 'CPSZ': {'00006413', '00008615', '00005347', '00005479'}, 'FNSZ': {'00010547', '00005479', '00004596', '00009697', '00006440', '00001479', '00006563', '00007584', '00009570', '00008174', '00006444', '00001548', '00009842', '00003760', '00007196', '00003884', '00005346', '00010062', '00001116', '00006507'}, 'GNSZ': {'00006563', '00005034', '00008174', '00009162', '00010020', '00006440', '00010062'}, 'SPSZ': set(), 'TCSZ': {'00005804'}, 'TNSZ': {'00008444'}}\n"
     ]
    }
   ],
   "source": [
    "table_test = {'ABSZ':set(),'CPSZ':set(), 'FNSZ':set(), 'GNSZ':set(), 'SPSZ':set(), 'TCSZ':set(), 'TNSZ':set()}\n",
    "for file in test_set:\n",
    "    stype = file.split('_')[-1][:4]\n",
    "    pid = file.split('_')[3]\n",
    "    table_test[stype].add(pid)\n",
    "   \n",
    "print(table_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fbc42971",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'szr_1896_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1897_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1898_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1899_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1900_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1901_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1902_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1903_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1904_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1905_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1906_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1907_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1908_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1909_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1910_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1911_pid_00008444_type_TNSZ.pkl',\n",
       " 'szr_1912_pid_00008444_type_TNSZ.pkl'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_set).intersection(set(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dccb803",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = list(set(train_set) - set(train_set).intersection(set(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c9cb683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(train_set).intersection(set(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed69226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('patient_wise_train.npy', train_set)\n",
    "np.save('patient_wise_test.npy', test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "852dab19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a5ea99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1657"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18e26f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_id_before, test_id_after, test_label_before, test_label_after = [],[],[],[],[]\n",
    "samples_test = 0\n",
    "\n",
    "for j in range(len(test_set)): #read train data, train label and patient id from the pkl files.\n",
    "        path_test = source + test_set[j]  #location of the pkl files\n",
    "        sz = pickle.load(open(path_test, 'rb'))  #load the file\n",
    "        samples_test  +=  np.shape(sz.data)[0] #the number of EEG clips in each pkl files\n",
    "        test_id_before.append(sz.patient_id)   #original patient id\n",
    "        test_id_after.append([sz.patient_id]*np.shape(sz.data)[0])   #expended patient id according to the number of EEG clips in each pkl file\n",
    "        test_label_before.append(sz.seizure_type)   #original label\n",
    "        test_label_after.append([sz.seizure_type]*np.shape(sz.data)[0]) #expended training lables according to the number of EEG clips in each pkl file\n",
    "        test_data.append(sz.data)\n",
    "       # print(sz.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bd511a23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_id_before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d7d8635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97804"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ab4b316",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_test_id_after = [item for sublist in test_id_after for item in sublist]   #concatenate the expended patient id\n",
    "flat_test_label_after = [item for sublist in test_label_after for item in sublist] #concatenate the expended train label\n",
    "flat_test_data = [item for sublist in test_data for item in sublist]  #concatenate the training data\n",
    "test_data = np.reshape(flat_test_data,[samples_test,1,20,24])\n",
    "\n",
    "np.save('patient_wise/test_data', test_data)\n",
    "np.save('patient_wise/test_label_before', test_label_before)\n",
    "np.save('patient_wise/test_label_after', flat_test_label_after)\n",
    "np.save('patient_wise/test_id_before', test_id_before)\n",
    "np.save('patient_wise/test_id_afte', flat_test_id_after)\n",
    "np.save('patient_wise/filename_test', test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11acd7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_id_before, train_id_after, train_label_before, train_label_after = [],[],[],[],[]\n",
    "samples_train = 0\n",
    "\n",
    "for j in range(len(train_set)): #read train data, train label and patient id from the pkl files.\n",
    "        path_train = source + train_set[j]  #location of the pkl files\n",
    "        sz = pickle.load(open(path_train, 'rb'))  #load the file\n",
    "        samples_train  +=  np.shape(sz.data)[0] #the number of EEG clips in each pkl files\n",
    "        train_id_before.append(sz.patient_id)   #original patient id\n",
    "        train_id_after.append([sz.patient_id]*np.shape(sz.data)[0])   #expended patient id according to the number of EEG clips in each pkl file\n",
    "        train_label_before.append(sz.seizure_type)   #original label\n",
    "        train_label_after.append([sz.seizure_type]*np.shape(sz.data)[0]) #expended training lables according to the number of EEG clips in each pkl file\n",
    "        train_data.append(sz.data)\n",
    "        \n",
    "flat_train_id_after = [item for sublist in train_id_after for item in sublist]   #concatenate the expended patient id\n",
    "flat_train_label_after = [item for sublist in train_label_after for item in sublist] #concatenate the expended train label\n",
    "flat_train_data = [item for sublist in train_data for item in sublist]  #concatenate the training data\n",
    "train_data = np.reshape(flat_train_data,[samples_train,1,20,24])\n",
    "\n",
    "np.save('patient_wise/train_data', train_data)\n",
    "np.save('patient_wise/train_label_before', train_label_before)\n",
    "np.save('patient_wise/train_label_after', flat_train_label_after)\n",
    "np.save('patient_wise/train_id_before', train_id_before)\n",
    "np.save('patient_wise/train_id_afte', flat_train_id_after)\n",
    "np.save('patient_wise/filename_train', train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "138e0984",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_all = test_set #np.load('patient_wise/filename_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "afbbf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_test = 0\n",
    "each_lenth_test, accumulated_test = [], [0]\n",
    "\n",
    "for j in range(len(test_all)):  #read validation data, validation label and patient id from the pkl files.\n",
    "    path_test = source + test_all[j]\n",
    "    sz = pickle.load(open(path_test, 'rb'))\n",
    "    each_lenth_test.append(np.shape(sz.data)[0])\n",
    "    samples_test  +=  np.shape(sz.data)[0]\n",
    "    accumulated_test.append(samples_test)\n",
    "\n",
    "accumulated_test = accumulated_test[:-1]\n",
    "np.save('patient_wise/accumulated_test', accumulated_test)\n",
    "np.save('patient_wise/each_lenth_test', each_lenth_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2128b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
